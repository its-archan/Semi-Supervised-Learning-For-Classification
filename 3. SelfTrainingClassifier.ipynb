{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad1481f",
   "metadata": {},
   "source": [
    "### Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86efcce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.svm import SVC # for Support Vector Classification baseline model\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier # for Semi-Supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e08143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix,precision_score,\\\n",
    "recall_score,roc_auc_score,classification_report,fbeta_score,precision_recall_curve,roc_curve,log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8847ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore') #we don't wanna see that\n",
    "np.random.seed(1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b742bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing datasets:\n",
    "train = pd.read_csv('C:/Users/MBBLABS/Desktop/Python/1. Models/3. Project/Data/less_feature/train.csv',index_col='Unnamed: 0')\n",
    "test = pd.read_csv('C:/Users/MBBLABS/Desktop/Python/1. Models/3. Project/Data/less_feature/test.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead81d5",
   "metadata": {},
   "source": [
    "### Preprocessing: \n",
    "#### 1. Changing data type <br> 2. splitting data <br> 3. assigning label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data's 'y' is of float type - lets change it's type to integer\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the data\n",
    "display(train.head(2))\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7546aab3",
   "metadata": {},
   "source": [
    "#### Assigning '-1' as label to the unlablled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ac41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train['y'].isnull()]['y']\n",
    "train['y'] = train['y'].fillna(-1)\n",
    "train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadaaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "1834/166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b380fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data type chaged to int32\n",
    "train['y'] = train['y'].astype('int32')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ce570",
   "metadata": {},
   "source": [
    "#### -- For training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating X,y:\n",
    "X = train.iloc[:,:-1] \n",
    "y = train.iloc[:,-1] #it's a mixure of all data\n",
    "\n",
    "#separating X,y with label\n",
    "X_lbl = train[train['y']!=-1].iloc[:,:-1]\n",
    "y_lbl = train[train['y']!=-1].iloc[:,-1]\n",
    "X_lbl.shape,y_lbl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d3989",
   "metadata": {},
   "source": [
    "#### -- For test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:,:-1] \n",
    "y_test = test.iloc[:,-1] \n",
    "X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f8ea2",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6417f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe to store results\n",
    "index = ['Algorithm', 'ROC AUC']\n",
    "results = pd.DataFrame(columns=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression:\n",
    "logreg = LogisticRegression(random_state=1, class_weight='None')\n",
    "logreg.fit(X_lbl, y_lbl)\n",
    "results = results.append(pd.Series(['Logistic Regression', roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1])], \n",
    "                                   index=index), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f34c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying result of logistic regression\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6fed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test data\n",
    "pred_test = logreg.predict(X_test)\n",
    "\n",
    "#Calculating and printing the f1 score \n",
    "f1_test = f1_score(y_test, pred_test)\n",
    "print('The f1 score for the testing data:', f1_test)\n",
    "\n",
    "#Ploting the confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test, pred_test),annot=True,fmt='d',cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697dde7",
   "metadata": {},
   "source": [
    "#### Classification Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3e182",
   "metadata": {},
   "source": [
    "#### Threshold tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs, threshold):\n",
    "               return (pos_probs >= threshold)\n",
    " \n",
    "y_prob = logreg.predict_proba(X_test)[:,1]\n",
    " \n",
    "thresholds = np.arange(0, 1, 0.01)\n",
    "scores = [f1_score(y_test, to_labels(y_prob, t)) for t in thresholds]\n",
    "\n",
    "# get best threshold\n",
    "ix = np.argmax(scores)\n",
    "print('Threshold=%.3f, F1-Score=%.5f' % (thresholds[ix], scores[ix]))\n",
    "\n",
    "\n",
    "plt.plot(thresholds, scores)\n",
    "plt.title('F1-score vs Threshold ')\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('F1-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11891e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_tuned = to_labels(y_prob, 0.430)\n",
    "print(classification_report(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20567259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision \n",
    "pr =  precision_score(y_test,y_pred_tuned)\n",
    "#recall\n",
    "re = recall_score(y_test,y_pred_tuned)\n",
    "#accuracy\n",
    "acc = accuracy_score(y_test,y_pred_tuned)\n",
    "\n",
    "pr,re,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64be1224",
   "metadata": {},
   "source": [
    "## Self-Training Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff943d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_svc =  LogisticRegression()\n",
    "\n",
    "# Specify Self-Training model parameters\n",
    "self_training_model = SelfTrainingClassifier(base_estimator=model_svc,\n",
    "                                             threshold=0.95, # default=0.75, The decision threshold for use with criterion='threshold'. Should be in [0, 1).\n",
    "                                             criterion='threshold', # {‘threshold’, ‘k_best’}, default=’threshold’, The selection criterion used to select which labels to add to the training set. If 'threshold', pseudo-labels with prediction probabilities above threshold are added to the dataset. If 'k_best', the k_best pseudo-labels with highest prediction probabilities are added to the dataset.\n",
    "                                             #k_best=5, # default=10, The amount of samples to add in each iteration. Only used when criterion='k_best'.\n",
    "                                             max_iter=500, # default=10, Maximum number of iterations allowed. Should be greater than or equal to 0. If it is None, the classifier will continue to predict labels until no new pseudo-labels are added, or all unlabeled samples have been labeled.\n",
    "                                             verbose=True \n",
    "                                            )\n",
    "\n",
    "# Fit the model\n",
    "clf_ST = self_training_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation \n",
    "print('')\n",
    "print('---------- Self Training Model - Summary ----------')\n",
    "print('Base Estimator: ', clf_ST.base_estimator_)\n",
    "print('Classes: ', clf_ST.classes_)\n",
    "print('Transduction Labels: ', clf_ST.transduction_)\n",
    "#print('Iteration When Sample Was Labeled: ', clf_ST.labeled_iter_)\n",
    "print('Number of Features: ', clf_ST.n_features_in_)\n",
    "print('Feature Names: ', clf_ST.feature_names_in_)\n",
    "print('Number of Iterations: ', clf_ST.n_iter_)\n",
    "print('Termination Condition: ', clf_ST.termination_condition_)\n",
    "print('')\n",
    "\n",
    "print('---------- Self Training Model - Evaluation on Test Data ----------')\n",
    "accuracy_score_ST = clf_ST.score(X_test, y_test)\n",
    "print('Accuracy Score: ', accuracy_score_ST)\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y_test, clf_ST.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy score: {accuracy_score(y_test,clf_ST.predict(X_test))},\\nprecision:{precision_score(y_test,clf_ST.predict(X_test))},\\nrecall: {recall_score(y_test,clf_ST.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93faffc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_svc = SVC(kernel='rbf', \n",
    "                probability=True, # Need to enable to be able to use predict_proba\n",
    "                C=1.0, # default = 1.0\n",
    "                gamma='scale', # default = 'scale',\n",
    "                random_state=0\n",
    "               )\n",
    "\n",
    "# Specify Self-Training model parameters\n",
    "self_training_model = SelfTrainingClassifier(base_estimator=model_svc,\n",
    "                                             threshold=.9, # default=0.75, The decision threshold for use with criterion='threshold'. Should be in [0, 1).\n",
    "                                             criterion='threshold', # {‘threshold’, ‘k_best’}, default=’threshold’, The selection criterion used to select which labels to add to the training set. If 'threshold', pseudo-labels with prediction probabilities above threshold are added to the dataset. If 'k_best', the k_best pseudo-labels with highest prediction probabilities are added to the dataset.\n",
    "                                             #k_best=50, # default=10, The amount of samples to add in each iteration. Only used when criterion='k_best'.\n",
    "                                             max_iter=100, # default=10, Maximum number of iterations allowed. Should be greater than or equal to 0. If it is None, the classifier will continue to predict labels until no new pseudo-labels are added, or all unlabeled samples have been labeled.\n",
    "                                             verbose=True \n",
    "                                            )\n",
    "\n",
    "# Fit the model\n",
    "clf_ST = self_training_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e47172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation \n",
    "print('')\n",
    "print('---------- Self Training Model - Summary ----------')\n",
    "print('Base Estimator: ', clf_ST.base_estimator_)\n",
    "print('Classes: ', clf_ST.classes_)\n",
    "print('Transduction Labels: ', clf_ST.transduction_)\n",
    "#print('Iteration When Sample Was Labeled: ', clf_ST.labeled_iter_)\n",
    "print('Number of Features: ', clf_ST.n_features_in_)\n",
    "print('Feature Names: ', clf_ST.feature_names_in_)\n",
    "print('Number of Iterations: ', clf_ST.n_iter_)\n",
    "print('Termination Condition: ', clf_ST.termination_condition_)\n",
    "print('')\n",
    "\n",
    "print('---------- Self Training Model - Evaluation on Test Data ----------')\n",
    "accuracy_score_ST = clf_ST.score(X_test, y_test)\n",
    "print('Accuracy Score: ', accuracy_score_ST)\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y_test, clf_ST.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ba941",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, clf_ST.predict(X_test)),annot=True,fmt='d',cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ([a1,a2]) = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, pred_test),annot=True,fmt='d',cmap = 'Blues',ax = a1)\n",
    "a1.set_title('Surpervised_threshold_tuned')\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, clf_ST.predict(X_test)),annot=True,fmt='d',cmap = 'Blues',ax = a2)\n",
    "a2.set_title('Self_training_classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
